{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac07b89",
   "metadata": {},
   "source": [
    "Q.1 What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Ans. Web scraping is the process of using bots to extract content and data from a website. Unlike screen scraping, which only copies pixels displayed onscreen, web scraping extracts underlying HTML code and, with it, data stored in a database. The scraper can then replicate entire website content elsewhere.\n",
    "\n",
    "* Search engine bots crawling a site, analyzing its content and then ranking it.\n",
    "\n",
    "* Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
    "\n",
    "* Market research companies using scrapers to pull data from forums and social media (e.g., for sentiment analysis).\n",
    "\n",
    "* Web scraping is also used for illegal purposes, including the undercutting of prices and the theft of copyrighted content.\n",
    "\n",
    "* An online entity targeted by a scraper can suffer severe financial losses, especially if itâ€™s a business strongly relying on competitive pricing models or deals in content distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238754a3",
   "metadata": {},
   "source": [
    "Q.2 What are the different methods used for Web Scraping?\n",
    "\n",
    "Ans. Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37492175",
   "metadata": {},
   "source": [
    "Q.3 What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Ans.\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.\n",
    "\n",
    "     Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350dd2d0",
   "metadata": {},
   "source": [
    "Q.4 Why is flask used in this Web Scraping project?\n",
    "\n",
    "Ans. Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff2de7",
   "metadata": {},
   "source": [
    "Q.5 Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "Ans. \n",
    "AWS Cloud Products\n",
    "\n",
    "* Compute.\n",
    "\n",
    "* Storage.\n",
    "\n",
    "* Database.\n",
    "\n",
    "* Networking & Content Delivery.\n",
    "\n",
    "* Analytics.\n",
    "\n",
    "* Machine Learning.\n",
    "\n",
    "* Security, Identity, & Compliance.\n",
    "\n",
    "1. compute - Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers.\n",
    "\n",
    "2. storage - \n",
    "AWS storage services\n",
    "\n",
    "* Data migration. AWS DataSync. Online data transfer service that optimizes network bandwidth and accelerates data movement between on-premises storage and AWS storage. ...\n",
    "\n",
    "* Hybrid cloud storage and edge computing. AWS Storage Gateway. ...\n",
    "\n",
    "* Disaster recovery and backup. AWS Elastic Disaster Recovery (DRS)\n",
    "\n",
    "3. database - Every application needs a place to store data from users, devices, and the application itself. Databases are important backend systems that are used to store, manage, update, and analyze data for all types of applications, from small back-office systems to mobile and consumer web applications with global scale.\n",
    "\n",
    "4. Networking & Content Delivery - \n",
    "Amazon CloudFront is a content delivery network (CDN) service built for high performance, security, and developer convenience.\n",
    "\n",
    "5. Analytics - \n",
    "AWS analytics services\n",
    "\n",
    "* Interactive analytics. Amazon Athena.\n",
    "\n",
    "* Big data processing. Amazon EMR.\n",
    "\n",
    "* Data warehousing. Amazon Redshift.\n",
    "\n",
    "* Interactive analytics. Amazon Kinesis.\n",
    "\n",
    "* Operational analytics. Amazon OpenSearch Service.\n",
    "\n",
    "* Dashboards and visualizations. Amazon Quicksight.\n",
    "\n",
    "* Visual data preparation. AWS Glue DataBrew.\n",
    "\n",
    "6. Machine Learning - \n",
    "Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly.\n",
    "\n",
    "7. Security, Identity, & Compliance - \n",
    "AWS Artifact is your go-to, central resource for compliance-related information that matters to you. It provides on-demand access to AWS security and compliance reports and select online agreements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff57bf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
